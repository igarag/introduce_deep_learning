{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning using TensorFlow and Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a brief introduction to deep learning and machine learning combined theory and practises. It is based on a YouTube channel \"Sentdex\" and its turorials on DeepLearning and MachineLearning. Each exercise will be explained using Jupyter which will allow us to execute the program step by step.\n",
    "\n",
    "In these exercises we are using some frameworks such as: **TensorFlow** and **Keras** using **Python** as language in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the dataset of images 28x28 size of hand-written digits 0-9 **mnist**.\n",
    "\n",
    "![nmist image](img/nmist_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the training and test variables. `x_train` containt the 28x28 imagen and `y_train` contains the **tag associated** with the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the data import `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Tag associated with the image: \" + str(y_train[0]))\n",
    "\n",
    "plt.imshow(x_train[0]) # Show the content of image.\n",
    "#print(x_train[0])    # Contains a multidimensional Array with the images values (from 0 to 255 values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the image to black and white by adding an atribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the previous cell, all the values in the image are between 0 and 255. Let's normalize the values to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
    "\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model to be used to solve the problem will now be specified. The **'Sequential'** model will be used, which has the following characteristics (extracted from the Keras documentation):\n",
    "\n",
    "The Sequential model is a linear stack of layers.\n",
    "\n",
    "You can create a Sequential model by passing a list of layer instances to the constructor:\n",
    "\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "```\n",
    "\n",
    "`Softmax` function calculates the probability of each possible label. By choosing the most likely one we have the neural network prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the most complex part. The model description. In this example we are going to use a hidden layer. The consequence of using a **single** hidden layer is the **precision** that the model will have in each of the periods. The **more layers** added the **more accurate** (or less error) the result will be.\n",
    "\n",
    "***We must be careful not to overtrain the model and lose its capacity for generalization.***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Information about the `adam` optimizer model can be read at this [link](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # 128 neurons in the hidden layer\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # 128 neurons in the hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))  # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is built with the directive `compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy', # Error\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(x_train, y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate validation loss and validation accuracy to evaluate how good the model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Loss: \" + str(val_loss) + \" - Accuracy: \" + str(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load models as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('models/epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the probability distribution, the most likely input value would be this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data returned is not very friendly, we can use the numpy library to return the most likely argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0])) # The prediction of the next x_test is a: '7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "In order to know if the number of neurons used and the intermediate layers have been adequate, we are going to represent in a table what would have happened if we had used another configuration.\n",
    "\n",
    "| Nº of neurons | Nº hidden layers | Loss       | Accuracy   | nº epoch | Avg. Time per epoch |\n",
    "| ------------- | ---------------- | ---------- | ---------- | -------- | ------------------- |\n",
    "| 128           | 1                | 0.1053     | 0.9692     | 3        | 3 seconds           |\n",
    "| **128**       | **2**            | **0.0915** | **0.9724** | **3**    | **3 seconds**       |\n",
    "| 128           | 3                | 0.0958     | 0.9688     | 3        | 3 seconds           |\n",
    "| **256**       | **1**            | **0.0904** | **0.9738** | **3**    | **4 seconds**       |\n",
    "| 256           | 2                | 0.0871     | 0.9735     | 3        | 5 seconds           |\n",
    "| 256           | 3                | 0.0785     | 0.9749     | 3        | 6 seconds           |\n",
    "| 512           | 1                | 0.0864     | 0.9733     | 3        | 7 seconds           |\n",
    "| 512           | 2                | 0.0738     | 0.9777     | 3        | 12 seconds          |\n",
    "| 512           | 3                | 0.0932     | 0.9724     | 3        | 16 seconds          |\n",
    "\n",
    "As can be seen, the most optimal in terms of accuracy and execution time are those marked in bold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the first tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
